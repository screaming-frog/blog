{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"The Mechanical Jerk\"\n",
    "> \"AI for evil\"\n",
    "- comments: true\n",
    "- categories: [ml, nlp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Sometimes, the anonynimity of the internet relieves whatever societal pressure skewing the battle between superego and id, causing the cesspits we see on Twitter, Reddit, and any other place people talk to each other. I wanted to do something about the rage-inducing interactions between two people who see each other as faceless 'others' where people dehumanise others for not sharing their viewpoint and are, therefore, morons.\n",
    "\n",
    "I thought a good idea would be to put my natural language processing (NLP) skillset into use. Have you ever heard of the saying 'you can't win a fight against a heavy bag'? Well what about if the heavy bag could also goad you into a fight as well as hit back? My plan was to finetune a medium sized GPT-2 model such that it could argue with people coherently online and place this model inside bots that could interact with Twitter and Reddit like I'm a modern day Rabbi Loew. By siccing my golems on people who are engaged in flame wars and making the existence of these bots known, I hope to discourage excessive toxicity and raise awareness. After all, if the idiot you're arguing with might be a pile of linear algebra, what's the point in getting angry.\n",
    "\n",
    "Of course, all of this is nonsense post-hoc justification for me to watch people get angry and scream impotently into the abyss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "I'm using GPT-2 a transformer model developed by OpenAI using generative pretraining to allow for unsupervised training on text. So similarly to how convolutional neural networks can be pretrained on ImageNet or some large image dataset and finetuned on a much smaller dataset, GPT-2 does the same for language. The objective during pretraining is to simply predict the next word given the preceding text. This is useful because text is rather abundant and usually unlabelled. For more information, read the original paper https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf or one of the multitude of blog posts on the subject.\n",
    "\n",
    "During finetuning, the model is given a comment and the objective is to iteratively predict the next word in the response to the comment until the \"&lt; endoftext>\" token is predicted, denoting the end of the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For my training data, I chose to use the Internet Argument Corpus provided by UC Santa Cruz https://nlds.soe.ucsc.edu/iac. The dataset consists of roughly 73,000,000 words of forum debates on all the juicy topics such as gun control, abortion, the existence of a god, and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I trim the fat from the corpus, leaving only the text, discussion id, id, and parent id for each comment. Then come some  preprocessing steps, such as removing posts containing quotations of other posts. This could be parsed properly, cleaned up and included but there's such an abundance of data that it's not necessary. Then it's just cleaning up some '\\n' newline characters and random slashes. We randomly sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discussion_id</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2049</td>\n",
       "      <td>4</td>\n",
       "      <td>Yeah, he had a recession, and his tax cuts mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2050</td>\n",
       "      <td>4</td>\n",
       "      <td>They cut the deficit by 70 thousand million......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15235</td>\n",
       "      <td>13912</td>\n",
       "      <td>The US is still the closest thing to a pure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i just thought that it would be cool to revive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>517</td>\n",
       "      <td>4</td>\n",
       "      <td>capitalism in theory allows people to have equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111563</td>\n",
       "      <td>14532</td>\n",
       "      <td>409477</td>\n",
       "      <td>409473</td>\n",
       "      <td>It's now legal for people to carry their guns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111564</td>\n",
       "      <td>14532</td>\n",
       "      <td>409505</td>\n",
       "      <td>409487</td>\n",
       "      <td>Whoops! I was wrong. Instead of ad hominem a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111565</td>\n",
       "      <td>14532</td>\n",
       "      <td>409483</td>\n",
       "      <td>409477</td>\n",
       "      <td>Not to come off negatively, NATO, but you are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111566</td>\n",
       "      <td>14532</td>\n",
       "      <td>409487</td>\n",
       "      <td>409483</td>\n",
       "      <td>The refuse to address that such an animal ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111567</td>\n",
       "      <td>14532</td>\n",
       "      <td>409489</td>\n",
       "      <td>409487</td>\n",
       "      <td>We have coyotes just outside the yard almost e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110613 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        discussion_id      id  parent_id  \\\n",
       "0                   4    2049          4   \n",
       "1                   4    2050          4   \n",
       "2                   4   15235      13912   \n",
       "3                   4       4          0   \n",
       "4                   4     517          4   \n",
       "...               ...     ...        ...   \n",
       "111563          14532  409477     409473   \n",
       "111564          14532  409505     409487   \n",
       "111565          14532  409483     409477   \n",
       "111566          14532  409487     409483   \n",
       "111567          14532  409489     409487   \n",
       "\n",
       "                                                     text  \n",
       "0       Yeah, he had a recession, and his tax cuts mov...  \n",
       "1       They cut the deficit by 70 thousand million......  \n",
       "2         The US is still the closest thing to a pure ...  \n",
       "3       i just thought that it would be cool to revive...  \n",
       "4       capitalism in theory allows people to have equ...  \n",
       "...                                                   ...  \n",
       "111563  It's now legal for people to carry their guns ...  \n",
       "111564    Whoops! I was wrong. Instead of ad hominem a...  \n",
       "111565  Not to come off negatively, NATO, but you are ...  \n",
       "111566    The refuse to address that such an animal ev...  \n",
       "111567  We have coyotes just outside the yard almost e...  \n",
       "\n",
       "[110613 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "posts = pd.read_csv('posts_lite.csv')\n",
    "posts.fillna(value = 0, inplace = True)\n",
    "posts.parent_id = posts.parent_id.astype(int)\n",
    "posts = posts.loc[~posts.text.str.contains('QUOTE')]\n",
    "posts['text'] = posts.text.str.replace('\\n','')\n",
    "posts['text'] = posts.text.str.replace(\"\\\\\\'\",\"'\")\n",
    "posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I parse these debate threads into parent and response pairs, sample 40000 pairs and concatenate them, inserting the special seperator characters that will allow GPT-2 to understand which bits are the parent and which are the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>i just thought that it would be cool to revive...</td>\n",
       "      <td>I never denied that it didn't. But that was a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>i just thought that it would be cool to revive...</td>\n",
       "      <td>Capitolism sucks, unfortunately people are bli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i just thought that it would be cool to revive...</td>\n",
       "      <td>unemployment did not decrease during reagans a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i just thought that it would be cool to revive...</td>\n",
       "      <td>I'll give to the poor when and if I want to. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>i just thought that it would be cool to revive...</td>\n",
       "      <td>capitalism in theory allows people to have equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>Source: Merriam-Webster Dictionary of Law, ...</td>\n",
       "      <td>Hmmm perhaps I used the wrong word. I meant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>No it definitly goes deeper than that.  It is ...</td>\n",
       "      <td>Are you looking for an answer from a creationi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>I am aware of this, the UK doesn't have any s...</td>\n",
       "      <td>Since you are not a citizen of the USA, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>bootfitter, just responding to jitobear and I ...</td>\n",
       "      <td>Of course you may respond to whomever you wis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Exactly.   And what standard definition is th...</td>\n",
       "      <td>I think that syklopps's point in asking jitobe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               parent  \\\n",
       "0   i just thought that it would be cool to revive...   \n",
       "1   i just thought that it would be cool to revive...   \n",
       "2   i just thought that it would be cool to revive...   \n",
       "3   i just thought that it would be cool to revive...   \n",
       "4   i just thought that it would be cool to revive...   \n",
       "..                                                ...   \n",
       "95     Source: Merriam-Webster Dictionary of Law, ...   \n",
       "96  No it definitly goes deeper than that.  It is ...   \n",
       "97   I am aware of this, the UK doesn't have any s...   \n",
       "98  bootfitter, just responding to jitobear and I ...   \n",
       "99   Exactly.   And what standard definition is th...   \n",
       "\n",
       "                                                child  \n",
       "0   I never denied that it didn't. But that was a ...  \n",
       "1   Capitolism sucks, unfortunately people are bli...  \n",
       "2   unemployment did not decrease during reagans a...  \n",
       "3   I'll give to the poor when and if I want to. I...  \n",
       "4   capitalism in theory allows people to have equ...  \n",
       "..                                                ...  \n",
       "95    Hmmm perhaps I used the wrong word. I meant ...  \n",
       "96  Are you looking for an answer from a creationi...  \n",
       "97    Since you are not a citizen of the USA, you ...  \n",
       "98   Of course you may respond to whomever you wis...  \n",
       "99  I think that syklopps's point in asking jitobe...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "def get_pairs(posts):\n",
    "    pairs = pd.DataFrame()\n",
    "    for i in np.unique(posts['discussion_id'].values):\n",
    "        disc = posts.loc[posts['discussion_id']==i]\n",
    "        for i, row in disc.iterrows():\n",
    "            children = disc.loc[disc['parent_id']==row['id']]\n",
    "            pairs = pairs.append(pd.DataFrame(zip([row.text]*children.shape[0], children.text.values)), ignore_index=True)\n",
    "    pairs.columns = ['parent', 'child']\n",
    "    return pairs\n",
    "posts = posts.sample(10000)\n",
    "pairs = get_pairs(posts)\n",
    "pairs.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = ''.join((pairs.parent+' ||| '+pairs.child+' <endoftext> ').values)\n",
    "Path(\"input-text.txt\").write_text(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Thank god for Docker. The days of worrying about versions of CUDA, CUDNN, Nvidia drivers and Tensorflow being incompatible are over. All training was done in a Docker container on a Google Cloud instance with a beefy V100 GPU attached. My RTX 2060 Super didn't have enough VRAM even when using half-precision. Using Google Cloud spared me from having to deal with the instability of Colab and was a good way to burn the rest of my free credit before it expired. Training was run for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
